{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efe15863",
   "metadata": {},
   "source": [
    "# Spaceship Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9c098a",
   "metadata": {},
   "source": [
    "#### Kaggle:\n",
    "Welcome to the year 2912, where your data science skills are needed to solve a cosmic mystery. We've received a transmission from four lightyears away and things aren't looking good.\n",
    "\n",
    "The Spaceship Titanic was an interstellar passenger liner launched a month ago. With almost 13,000 passengers on board, the vessel set out on its maiden voyage transporting emigrants from our solar system to three newly habitable exoplanets orbiting nearby stars.\n",
    "\n",
    "While rounding Alpha Centauri en route to its first destination—the torrid 55 Cancri E—the unwary Spaceship Titanic collided with a spacetime anomaly hidden within a dust cloud. Sadly, it met a similar fate as its namesake from 1000 years before. Though the ship stayed intact, almost half of the passengers were transported to an alternate dimension!\n",
    "\n",
    "To help rescue crews and retrieve the lost passengers, you are challenged to predict which passengers were transported by the anomaly using records recovered from the spaceship’s damaged computer system.\n",
    "\n",
    "Help save them and change history!\n",
    "\n",
    "#### Me:\n",
    "Challenge accepted!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ec1298",
   "metadata": {},
   "source": [
    "Let's take a quick look to our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a37a2d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "740c2a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>9276_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/98/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Gravior Noxnuther</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>9278_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1499/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kurta Mondalley</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>9279_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/1500/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fayey Connon</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>9280_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>Celeon Hontichre</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>9280_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Propsh Hontichre</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "0        0001_01     Europa     False     B/0/P    TRAPPIST-1e  39.0  False   \n",
       "1        0002_01      Earth     False     F/0/S    TRAPPIST-1e  24.0  False   \n",
       "2        0003_01     Europa     False     A/0/S    TRAPPIST-1e  58.0   True   \n",
       "3        0003_02     Europa     False     A/0/S    TRAPPIST-1e  33.0  False   \n",
       "4        0004_01      Earth     False     F/1/S    TRAPPIST-1e  16.0  False   \n",
       "...          ...        ...       ...       ...            ...   ...    ...   \n",
       "8688     9276_01     Europa     False    A/98/P    55 Cancri e  41.0   True   \n",
       "8689     9278_01      Earth      True  G/1499/S  PSO J318.5-22  18.0  False   \n",
       "8690     9279_01      Earth     False  G/1500/S    TRAPPIST-1e  26.0  False   \n",
       "8691     9280_01     Europa     False   E/608/S    55 Cancri e  32.0  False   \n",
       "8692     9280_02     Europa     False   E/608/S    TRAPPIST-1e  44.0  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0             0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1           109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2            43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3             0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4           303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "...           ...        ...           ...     ...     ...                ...   \n",
       "8688          0.0     6819.0           0.0  1643.0    74.0  Gravior Noxnuther   \n",
       "8689          0.0        0.0           0.0     0.0     0.0    Kurta Mondalley   \n",
       "8690          0.0        0.0        1872.0     1.0     0.0       Fayey Connon   \n",
       "8691          0.0     1049.0           0.0   353.0  3235.0   Celeon Hontichre   \n",
       "8692        126.0     4688.0           0.0     0.0    12.0   Propsh Hontichre   \n",
       "\n",
       "      Transported  \n",
       "0           False  \n",
       "1            True  \n",
       "2           False  \n",
       "3           False  \n",
       "4            True  \n",
       "...           ...  \n",
       "8688        False  \n",
       "8689        False  \n",
       "8690         True  \n",
       "8691        False  \n",
       "8692         True  \n",
       "\n",
       "[8693 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e32552",
   "metadata": {},
   "source": [
    "### Statistical Hypothesis Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f1e41a",
   "metadata": {},
   "source": [
    "In order to continue with prediction algorithm, we should choose the specific features that have the highest correlation with \"Transported\" column.\n",
    "\n",
    "We need to test whether our data have a normal distribution or not. If it does so, then we will apply the parametric statistical hypothesis tests, and if not, we will continue with nonparametric statistical hypothesis tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8dfb34f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerical data\n",
    "data_num1 = df[\"Age\"]\n",
    "data_num2 = df[\"RoomService\"]\n",
    "data_num3 = df[\"FoodCourt\"]\n",
    "data_num4 = df[\"ShoppingMall\"]\n",
    "data_num5 = df[\"Spa\"]\n",
    "data_num6 = df[\"VRDeck\"]\n",
    "\n",
    "#categorical data\n",
    "data_cat1 = df[\"HomePlanet\"]\n",
    "data_cat2 = df[\"CryoSleep\"]\n",
    "data_cat3 = df[\"Destination\"]\n",
    "data_cat4 = df[\"VIP\"]\n",
    "data_cat5 = df[\"Cabin\"]\n",
    "outcome_data = df[\"Transported\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "61b9d523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data 1 :\n",
      "stat=248.583, p=0.000\n",
      "Probably not Gaussian\n",
      " \n",
      "data 2 :\n",
      "stat=10480.443, p=0.000\n",
      "Probably not Gaussian\n",
      " \n",
      "data 3 :\n",
      "stat=11188.441, p=0.000\n",
      "Probably not Gaussian\n",
      " \n",
      "data 4 :\n",
      "stat=15648.109, p=0.000\n",
      "Probably not Gaussian\n",
      " \n",
      "data 5 :\n",
      "stat=11667.216, p=0.000\n",
      "Probably not Gaussian\n",
      " \n",
      "data 6 :\n",
      "stat=11847.700, p=0.000\n",
      "Probably not Gaussian\n",
      " \n",
      "data 7 :\n",
      "stat=nan, p=nan\n",
      "Probably not Gaussian\n",
      " \n",
      "data 8 :\n",
      "stat=nan, p=nan\n",
      "Probably not Gaussian\n",
      " \n",
      "data 9 :\n",
      "stat=nan, p=nan\n",
      "Probably not Gaussian\n",
      " \n",
      "data 10 :\n",
      "stat=nan, p=nan\n",
      "Probably not Gaussian\n",
      " \n",
      "data 11 :\n",
      "stat=nan, p=nan\n",
      "Probably not Gaussian\n",
      " \n",
      "data 12 :\n",
      "stat=29953.173, p=0.000\n",
      "Probably not Gaussian\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import normaltest\n",
    "\n",
    "column_list = [data_num1, data_num2, data_num3, data_num4, data_num5, data_num6,\n",
    "               data_cat1, data_cat2, data_cat3, data_cat4, data_cat5, outcome_data] \n",
    "def normality_test(column_list):\n",
    "    data_num = 0\n",
    "    for column in column_list:\n",
    "        data_num += 1\n",
    "        stat, p = normaltest(column)\n",
    "        print(\"data\", data_num,\":\")\n",
    "        print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "        if p > 0.05:\n",
    "            print('Probably Gaussian')\n",
    "        else:\n",
    "            print('Probably not Gaussian')\n",
    "        print(\" \")\n",
    "            \n",
    "normality_test(column_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75500099",
   "metadata": {},
   "source": [
    "As we see, our data does not meet the basic principles of \"Parametric Statistical Hypothesis Tests\", that is, it does not have the normal distribution. This means that we have to go on with the \"Nonparametric Statistical Hypothesis Tests\". By applying Spearman's Rank Correlation Test, we will see whether the \"quantitative\" data that we have is dependent on our outcome data, namely \"Transported\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6bedadf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comparison 1 :\n",
      "stat=-0.070, p=0.000\n",
      "Probably dependent\n",
      " \n",
      "comparison 2 :\n",
      "stat=-0.364, p=0.000\n",
      "Probably dependent\n",
      " \n",
      "comparison 3 :\n",
      "stat=-0.176, p=0.000\n",
      "Probably dependent\n",
      " \n",
      "comparison 4 :\n",
      "stat=-0.215, p=0.000\n",
      "Probably dependent\n",
      " \n",
      "comparison 5 :\n",
      "stat=-0.366, p=0.000\n",
      "Probably dependent\n",
      " \n",
      "comparison 6 :\n",
      "stat=-0.341, p=0.000\n",
      "Probably dependent\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "predictor_data = [data_num1, data_num2, data_num3, data_num4, data_num5, data_num6] \n",
    "outcome_datum = outcome_data\n",
    "\n",
    "def spearmanr_test(predictor_data_list, outcome_data):\n",
    "    data_num = 0\n",
    "    for data in predictor_data_list:\n",
    "        data_num += 1\n",
    "        stat, p = spearmanr(data, outcome_data)\n",
    "        print(\"comparison\", data_num, \":\")\n",
    "        print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "        if p > 0.05:\n",
    "            print('Probably independent')\n",
    "        else:\n",
    "            print('Probably dependent')\n",
    "        print(\" \")\n",
    "            \n",
    "spearmanr_test(predictor_data, outcome_datum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36908f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comparison 1 :\n",
      "stat=nan, p=nan\n",
      "Probably different distributions\n",
      " \n",
      "comparison 2 :\n",
      "stat=nan, p=nan\n",
      "Probably different distributions\n",
      " \n",
      "comparison 3 :\n",
      "stat=nan, p=nan\n",
      "Probably different distributions\n",
      " \n",
      "comparison 4 :\n",
      "stat=nan, p=nan\n",
      "Probably different distributions\n",
      " \n",
      "comparison 5 :\n",
      "stat=nan, p=nan\n",
      "Probably different distributions\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Kruskal-Wallis H Test\n",
    "from scipy.stats import kruskal\n",
    "predictor_cat_data = [data_cat1, data_cat2, data_cat3, data_cat4, data_cat5] \n",
    "outcome_datum = outcome_data\n",
    "\n",
    "def kruskal_test(predictor_data_list, outcome_data):\n",
    "    data_num = 0\n",
    "    for data in predictor_data_list:\n",
    "        data_num += 1\n",
    "        stat, p = kruskal(data, outcome_data)\n",
    "        print(\"comparison\", data_num, \":\")\n",
    "        print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "        if p > 0.05:\n",
    "            print('Probably the same distribution')\n",
    "        else:\n",
    "            print('Probably different distributions')\n",
    "        print(\" \")\n",
    "            \n",
    "kruskal_test(predictor_cat_data, outcome_datum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c32e2ac",
   "metadata": {},
   "source": [
    "To sum up, all ofthe numerical columns were related with the \"Transported\" column while categorical columns did not have a correlation with the \"Transported\" column. This means that we will continue with these categories: \"Age\", \"Spa\", \"RoomService\", \"ShoppingMall\", \"FoodCourt\" and \"VRDeck\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba72201",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a51f5ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3bbd1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df[[\"Age\", \"Spa\", \"RoomService\", \"ShoppingMall\", \"FoodCourt\", \"VRDeck\"]]\n",
    "Y= df[[\"Transported\"]]  # the target output\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.4,random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f52fa08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5215, 6)\n",
      "Age             112\n",
      "Spa             107\n",
      "RoomService     116\n",
      "ShoppingMall    133\n",
      "FoodCourt       117\n",
      "VRDeck          121\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Shape of training data (num_rows, num_columns)\n",
    "print(X_train.shape)\n",
    "\n",
    "# Number of missing values in each column of training data\n",
    "missing_val_count_by_column = (X_train.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d8fdcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Spa', 'RoomService', 'ShoppingMall', 'FoodCourt', 'VRDeck']\n"
     ]
    }
   ],
   "source": [
    "col_with_missing_values = [col for col in X_train.columns\n",
    "                             if X_train[col].isnull().any()]\n",
    "print(col_with_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8521c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "# Define imputer\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_freq = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "\n",
    "# Perform the imputation on 'your_column'\n",
    "df['Age'] = imp_mean.fit_transform(df['Age'].values.reshape(-1, 1))\n",
    "df['Spa'] = imp_freq.fit_transform(df['Spa'].values.reshape(-1, 1))\n",
    "df['RoomService'] = imp_mean.fit_transform(df['RoomService'].values.reshape(-1, 1))\n",
    "df['ShoppingMall'] = imp_mean.fit_transform(df['ShoppingMall'].values.reshape(-1, 1))\n",
    "df['FoodCourt'] = imp_mean.fit_transform(df['FoodCourt'].values.reshape(-1, 1))\n",
    "df['VRDeck'] = imp_mean.fit_transform(df['VRDeck'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "9c1bad7d-b5bb-4968-b662-6a9af05f1600",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df[[\"Age\", \"Spa\", \"RoomService\", \"ShoppingMall\", \"FoodCourt\", \"VRDeck\"]] \n",
    "Y= df[[\"Transported\"]]  # the target output\n",
    "passenger_ids = df['PassengerId'] # to keep track of passenger's IDs\n",
    "\n",
    "X_train,X_test,y_train,y_test, ids_train, ids_test = train_test_split(X,Y, passenger_ids, test_size = 4277/8693,\n",
    "                                                                      random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "db49b4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "col_with_missing_values = [col for col in X_train.columns\n",
    "                             if X_train[col].isnull().any()]\n",
    "print(col_with_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "90219abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4416, 6)\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Shape of training data (num_rows, num_columns)\n",
    "print(X_train.shape)\n",
    "\n",
    "# Number of missing values in each column of training data\n",
    "missing_val_count_by_column = (X_train.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48a8d07",
   "metadata": {},
   "source": [
    "### Prediction Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "3d8660a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/miniconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, ...,  True, False, False])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "44df288a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.60%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#y_pred_rounded = [round(value) for value in y_pred]\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "3cd45d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "model = xgb.XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "8b2b51c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.18%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred_rounded = [round(value) for value in y_pred]\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_rounded)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "b090c066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x3/pkxr6fs91b9dt9nf608j0q100000gn/T/ipykernel_2941/182599237.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train, y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, ...,  True, False, False])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "442fbe3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.74%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#y_pred_rounded = [round(value) for value in y_pred]\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "29e94384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "SOURCE = \"/Users/cagriertem/Desktop/PROJECTS AND TUTORIALS/Kaggle Spaceship Titanic\"\n",
    "df_submit = pd.DataFrame({'PassengerId': ids_test,'Transported': y_pred})\n",
    "df_submit.to_csv(os.path.join(SOURCE,\"submit.csv\"),index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26187110",
   "metadata": {},
   "source": [
    "Before we finish, let us test the neural network algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "6f916445-2a87-4591-bbc0-162bd5f67da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.09%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Converting data to PyTorch tensors\n",
    "X_train_torch = torch.from_numpy(X_train.to_numpy()).float()\n",
    "y_train_torch = torch.from_numpy(y_train.to_numpy()).float().view(-1, 1)  \n",
    "X_test_torch = torch.from_numpy(X_test.to_numpy()).float()\n",
    "y_test_torch = torch.from_numpy(y_test.to_numpy()).float().view(-1, 1)\n",
    "\n",
    "# Define the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(6, 288),  # Input layer with 6 neurons \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(288, 18), # Hidden layer with 8 neurons \n",
    "    nn.ReLU(),\n",
    "    nn.Linear(18, 1),  # Output layer with 1 neuron (binary classification)\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Set loss and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss for binary classification\n",
    "optimizer = torch.optim.Rprop(model.parameters())\n",
    "\n",
    "# Train the model\n",
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(X_train_torch)\n",
    "    loss = criterion(y_pred, y_train_torch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Evaluate the model\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_torch)\n",
    "    y_pred_cls = y_pred.round()\n",
    "    acc = y_pred_cls.eq(y_test_torch).sum().item() / y_test_torch.shape[0]\n",
    "    print(f'Accuracy: {acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "895060ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['False', 'False', 'True', ..., 'True', 'False', 'False'],\n",
       "      dtype='<U5')"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_cls_str = np.where(y_pred_cls==1, 'True', 'False')\n",
    "y_pred_cls_str.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "64c40f16-522d-4cd1-b96c-fc2906c68338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "SOURCE = \"/Users/cagriertem/Desktop/PROJECTS AND TUTORIALS/Kaggle Spaceship Titanic\"\n",
    "df_submit = pd.DataFrame({'PassengerId': ids_test,'Transported': y_pred_cls_str.ravel()})\n",
    "df_submit.to_csv(os.path.join(SOURCE,\"submit.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "cb5a1f39-20ce-4824-8449-38350ae0a6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6913</th>\n",
       "      <td>7330_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7066</th>\n",
       "      <td>7520_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8001</th>\n",
       "      <td>8559_03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>1281_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4442</th>\n",
       "      <td>4723_02</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3323</th>\n",
       "      <td>3567_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3389</th>\n",
       "      <td>3645_03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>1035_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4679</th>\n",
       "      <td>4987_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>1573_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId Transported\n",
       "6913     7330_01       False\n",
       "7066     7520_01       False\n",
       "8001     8559_03        True\n",
       "1200     1281_01        True\n",
       "4442     4723_02       False\n",
       "...          ...         ...\n",
       "3323     3567_01        True\n",
       "3389     3645_03        True\n",
       "976      1035_01        True\n",
       "4679     4987_01       False\n",
       "1483     1573_01       False\n",
       "\n",
       "[4277 rows x 2 columns]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb58513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b985ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
